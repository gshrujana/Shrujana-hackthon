{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WtaiCCTAeagY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LOAD   LIBRARIES**"
      ],
      "metadata": {
        "id": "9DMrOJZOedIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import chi2_contingency, stats\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, StratifiedKFold, cross_val_score\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler, ClusterCentroids, TomekLinks\n",
        "from imblearn.over_sampling import ADASYN\n"
      ],
      "metadata": {
        "id": "5yq2JhESercB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA PREPARATION**"
      ],
      "metadata": {
        "id": "kdDM18rKfamU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/sample_data/C&T train dataset (1).csv', usecols=['sno','acc_info','duration_month','credit_history','purpose','savings_acc','employment_st','personal_status','gurantors','resident_since','property_type','installment_type','housing_type','credits_no','job_type','liables','Group_no'])\n",
        "\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "y6Qv_QeFfrU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ENCODING**"
      ],
      "metadata": {
        "id": "jxHmtJamgbdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical variables to numerical values using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':\n",
        "        df[col] = label_encoder.fit_transform(df[col])\n",
        "\n",
        "print(df)\n",
        "# Drop rows with missing value\n",
        "df.dropna(inplace=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "S42luUmageix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***EXPLORATORY DATA ANALYSIS***"
      ],
      "metadata": {
        "id": "FCY_nAUEg4gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example Box Plot of Duration Month by Group_no\n",
        "print('Box Plot of Duration Month by Group_no')\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(x='Group_no', y='duration_month', data=df)\n",
        "plt.title('Box Plot of Duration Month by Group_no')\n",
        "plt.show()\n",
        "#Example pair plot with color-coded classes\n",
        "print('pair plot with color-coded classes')\n",
        "sns.pairplot(df, hue='Group_no', diag_kind='kde')\n",
        "plt.suptitle('Pair Plot with Class Color Coding')\n",
        "plt.show()\n",
        "# Histograms for each feature with 'Group_no' as hue\n",
        "print('Histograms for each feature with Group_no as hue')\n",
        "plt.figure(figsize=(12, 8))\n",
        "num_cols = min(len(df.columns[:-1]), 9)\n",
        "for i, col in enumerate(df.columns[:-1][:num_cols]):\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    sns.histplot(data=df, x=col, hue='Group_no', kde=True, palette='Set1')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Box plots for each feature with 'Group_no' as x-axis\n",
        "print('Box plots for each feature with Group_no as x-axis')\n",
        "plt.figure(figsize=(12, 8))\n",
        "num_cols = min(len(df.columns[:-1]), 9)\n",
        "for i, col in enumerate(df.columns[:-1][:num_cols]):\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    sns.boxplot(data=df, x='Group_no', y=col, palette='Set2')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Plot distribution of 'target_variable'\n",
        "sns.histplot(df['Group_no'])\n",
        "plt.title('Distribution of Group_no')\n",
        "plt.show()\n",
        "\n",
        "# Plot missing values\n",
        "sns.heatmap(df.isnull(), cbar=False)\n",
        "plt.title('Missing Values Heatmap')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Plot correlation matrix\n",
        "corr_matrix = df.corr()\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XumpqmTShcQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **UNIVARIATE ANALYSIS**"
      ],
      "metadata": {
        "id": "0Wyq_odemeey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Numeric Features\n",
        "numeric_features = ['sno', 'duration_month', 'credits_no', 'liables', 'resident_since']\n",
        "\n",
        "# Categorical Features\n",
        "categorical_features = ['acc_info', 'credit_history', 'purpose', 'savings_acc',\n",
        "                        'employment_st', 'personal_status', 'gurantors', 'property_type',\n",
        "                        'installment_type', 'housing_type', 'job_type']\n",
        "\n",
        "# Summary statistics for numeric features\n",
        "print(\"Summary statistics for numeric features:\")\n",
        "print(df[numeric_features].describe())\n",
        "\n",
        "# Histogram for numeric features\n",
        "df[numeric_features].hist(figsize=(12, 8))\n",
        "plt.suptitle(\"Histogram of Numeric Features\")\n",
        "plt.show()\n",
        "\n",
        "# Box plot for numeric features\n",
        "df[numeric_features].boxplot(figsize=(10, 6))\n",
        "plt.title(\"Boxplot of Numeric Features\")\n",
        "plt.show()\n",
        "\n",
        "# Frequency distribution for categorical features\n",
        "for feature in categorical_features:\n",
        "    print(\"\\nFrequency distribution for\", feature)\n",
        "    print(df[feature].value_counts())\n",
        "\n",
        "    # Bar plot for categorical features\n",
        "    df[feature].value_counts().plot(kind='bar', figsize=(8, 6))\n",
        "    plt.title(\"Bar plot of \" + feature)\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.show()\n",
        "\n",
        "    # Pie chart for categorical features\n",
        "    df[feature].value_counts().plot(kind='pie', autopct='%1.1f%%', figsize=(8, 8))\n",
        "    plt.title(\"Pie chart of \" + feature)\n",
        "    plt.ylabel(\"\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "g3_PapFFnccI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BIVARIATE ANALYSIS**"
      ],
      "metadata": {
        "id": "6ZH6FaSboMYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Numeric-Numeric relationships\n",
        "# Scatter plot matrix\n",
        "pd.plotting.scatter_matrix(df[numeric_features], figsize=(12, 12))\n",
        "plt.suptitle(\"Scatter Plot Matrix of Numeric Features\")\n",
        "plt.show()\n",
        "\n",
        "# Correlation matrix\n",
        "correlation_matrix = df[numeric_features].corr()\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
        "plt.title(\"Correlation Matrix of Numeric Features\")\n",
        "plt.show()\n",
        "\n",
        "# Categorical-Categorical relationships\n",
        "# Create contingency tables\n",
        "for feature1 in categorical_features:\n",
        "    for feature2 in categorical_features:\n",
        "        if feature1 != feature2:\n",
        "            contingency_table = pd.crosstab(df[feature1], df[feature2])\n",
        "            print(\"\\nContingency table for {} vs {}\".format(feature1, feature2))\n",
        "            print(contingency_table)\n",
        "            chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
        "            print(\"Chi-square test p-value:\", p)\n",
        "\n",
        "# Numeric-Categorical relationships\n",
        "# Box plot of numeric features vs categorical features\n",
        "for feature in categorical_features:\n",
        "    for num_feature in numeric_features:\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.boxplot(x=feature, y=num_feature, data=df)\n",
        "        plt.title(\"Box plot of {} vs {}\".format(feature, num_feature))\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "QnKGSLeUoTbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SPLITTING OF DATA**"
      ],
      "metadata": {
        "id": "3xnKoXFkiZIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = df.drop(\"Group_no\", axis=\"columns\")\n",
        "y = df['Group_no']\n",
        "\n",
        "# Split the data into training and testing sets using stratified sampling\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "z-fvtofLieyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODEL EVALUATION FUNCTION**"
      ],
      "metadata": {
        "id": "_4F2-CvpivE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize models including SVM\n",
        "models = [\n",
        "    ('Random Forest', RandomForestClassifier()),\n",
        "    ('Gradient Boosting', GradientBoostingClassifier()),\n",
        "    ('AdaBoost', AdaBoostClassifier()),\n",
        "    ('Extra Trees', ExtraTreesClassifier()),\n",
        "    ('SVM', SVC())\n",
        "]\n",
        "\n",
        "# Define parameter grid for SVM\n",
        "svm_param_dist = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n"
      ],
      "metadata": {
        "id": "Un8TfauQi0ZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CLASSIFICATION MODELS**"
      ],
      "metadata": {
        "id": "tnLnwFtRi7DU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate models including SVM\n",
        "results = {}\n",
        "for name, model in models:\n",
        "    if name == 'SVM':\n",
        "        random_search_svm = RandomizedSearchCV(estimator=model, param_distributions=svm_param_dist, n_iter=100, cv=5, random_state=42, n_jobs=-1)\n",
        "        random_search_svm.fit(X_train_scaled, y_train)\n",
        "        best_params_svm = random_search_svm.best_params_\n",
        "        model.set_params(**best_params_svm)\n",
        "\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "    else:\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results[name] = accuracy\n",
        "    print(f\"{name} Accuracy: {accuracy}\")\n",
        "    best_model_name = max(results, key=results.get)\n",
        "best_model =[model for model in models if model[0] == best_model_name][0][1]\n"
      ],
      "metadata": {
        "id": "qyOY3jqsjGze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODEL SELECTION**"
      ],
      "metadata": {
        "id": "P-VgqRGpjjte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the best model\n",
        "y_pred_best = best_model.predict(X_test_scaled)\n",
        "best_model_accuracy = accuracy_score(y_test, y_pred_best)\n",
        "print(f\"Best Model ({best_model_name}) Accuracy: {best_model_accuracy}\")\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "MQm03lPEjnIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Random Over Sampling to the training data\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_ros, y_ros = ros.fit_resample(X_scaled, y)\n",
        "\n",
        "# Apply Random Under Sampling to the training data\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_rus, y_rus = rus.fit_resample(X_ros, y_ros)\n",
        "\n",
        "# Apply SMOTE to the training data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_smote, y_smote = smote.fit_resample(X_rus, y_rus)\n",
        "\n",
        "# Apply ADASYN to the training data\n",
        "adasyn = ADASYN(random_state=42)\n",
        "X_adasyn, y_adasyn = adasyn.fit_resample(X_smote, y_smote)\n",
        "\n",
        "# Apply Cluster Centroids under sampling to the training data\n",
        "cc = ClusterCentroids(random_state=42)\n",
        "X_cc, y_cc = cc.fit_resample(X_adasyn, y_adasyn)\n",
        "\n",
        "# Apply Tomek Links under sampling to the training data\n",
        "tl = TomekLinks()\n",
        "X_tl, y_tl = tl.fit_resample(X_cc, y_cc)\n",
        "\n",
        "# Split the augmented data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tl, y_tl, test_size=0.2, random_state=42, stratify=y_tl)\n",
        "\n",
        "# Initialize and train the RandomForest model\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Accuracy with Multiple Data Augmentation Methods: {accuracy}\")"
      ],
      "metadata": {
        "id": "hQ9ghOlmj1Ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **APPLICATION ON TEST DATASET**"
      ],
      "metadata": {
        "id": "IDnLdjoBu0-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the test dataset\n",
        "test_df = pd.read_csv('/content/sample_data/C&T test dataset (1).csv',usecols=['sno','acc_info','duration_month','credit_history','purpose','savings_acc','employment_st','personal_status','gurantors','resident_since','property_type','installment_type','housing_type','credits_no','job_type','liables'])\n",
        "\n",
        "\n",
        "test_df.dropna(inplace=True)\n",
        "test_X = test_df\n",
        "\n",
        "# Convert categorical variables to numerical values using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "for col in test_X.columns:\n",
        "    if test_X[col].dtype == 'object':\n",
        "        test_X[col] = label_encoder.fit_transform(test_X[col])\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "test_X_scaled = scaler.fit_transform(test_X)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_classifier.predict(test_X_scaled)\n",
        "\n",
        "# Create a DataFrame with sno and predicted group_no\n",
        "result_df = pd.DataFrame({'Serial number': test_df['sno'], 'Group_no': y_pred})\n",
        "\n"
      ],
      "metadata": {
        "id": "pXXE7E1ppAC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CREATING SUBMISSION FILE**"
      ],
      "metadata": {
        "id": "uLhktSGau9UR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the result to a CSV file\n",
        "result_df.to_csv('SUBMISSION.csv', index=False)"
      ],
      "metadata": {
        "id": "11OFX5NYpNUu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}